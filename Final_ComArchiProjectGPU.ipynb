{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **The code is take from the following project and github repository.**\n",
        "[https://github.com/almarengo/gpt2-text-classification/tree/main\n",
        "](https://github.com/almarengo/gpt2-text-classification/tree/main)"
      ],
      "metadata": {
        "id": "kL00M5RqU32C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pynvml\n",
        "!pip install psutil\n",
        "!pip install Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ijaT-kyG-t1",
        "outputId": "6c6fce7b-c40f-4504-ce84-d0a637326602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml)\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-ml-py, pynvml\n",
            "Successfully installed nvidia-ml-py-12.560.30 pynvml-12.0.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer, TFGPT2Model\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import time\n",
        "import psutil\n",
        "import threading\n",
        "import csv\n",
        "import os\n",
        "\n",
        "CARBON_INTENSITY = 0.4\n",
        "RESULTS_CSV = \"energy_measurements_gpu.csv\"\n",
        "USE_GPU = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "\n",
        "def get_gpu_power():\n",
        "    if USE_GPU:\n",
        "        result = subprocess.run(\n",
        "            [\"nvidia-smi\", \"--query-gpu=power.draw\", \"--format=csv,nounits,noheader\"],\n",
        "            stdout=subprocess.PIPE, text=True)\n",
        "        return float(result.stdout.strip())\n",
        "    return 0.0\n",
        "\n",
        "def get_cpu_power_estimate():\n",
        "    cpu_util = psutil.cpu_percent()\n",
        "    estimated_cpu_power = (cpu_util / 100.0) * 50\n",
        "    return estimated_cpu_power\n",
        "\n",
        "def measure_energy_and_time(func, *args, **kwargs):\n",
        "    start_time = time.time()\n",
        "    energy_gpu_joules = 0.0\n",
        "    energy_cpu_joules = 0.0\n",
        "    interval = 0.1\n",
        "\n",
        "    def target():\n",
        "        func(*args, **kwargs)\n",
        "\n",
        "    thread = threading.Thread(target=target)\n",
        "    thread.start()\n",
        "\n",
        "    while thread.is_alive():\n",
        "        gpu_watts = get_gpu_power()\n",
        "        cpu_watts = get_cpu_power_estimate()\n",
        "        time.sleep(interval)\n",
        "        energy_gpu_joules += gpu_watts * interval\n",
        "        energy_cpu_joules += cpu_watts * interval\n",
        "\n",
        "    thread.join()\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_energy_joules = energy_gpu_joules + energy_cpu_joules\n",
        "    total_energy_kwh = total_energy_joules * 2.77778e-7\n",
        "    emissions_kg = total_energy_kwh * CARBON_INTENSITY\n",
        "\n",
        "    return total_time, total_energy_joules, emissions_kg\n",
        "\n",
        "def log_results(task_name, phase, total_time, energy_joules, emissions_kg, filename=RESULTS_CSV):\n",
        "    file_exists = os.path.isfile(filename)\n",
        "    with open(filename, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        if not file_exists:\n",
        "            writer.writerow([\"Task\", \"Phase\", \"Time(s)\", \"Energy(J)\", \"Emissions(kgCO2)\"])\n",
        "        writer.writerow([task_name, phase, total_time, energy_joules, emissions_kg])\n",
        "\n",
        "\n",
        "df = pd.read_csv('tweets_processed.csv')\n",
        "\n",
        "df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['lemmatized_tweets']\n",
        "y = df['VADER_sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
        "\n",
        "\n",
        "MAX_LENGTH = math.ceil((X_train.apply(lambda x: len(str(x).split())).mean()))+2\n",
        "\n",
        "PAD_TOKEN = \"<|pad|>\"\n",
        "EOS_TOKEN = \"<|endoftext|>\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",\n",
        "    pad_token=PAD_TOKEN,\n",
        "    eos_token=EOS_TOKEN,\n",
        "    max_length=MAX_LENGTH,\n",
        "    is_split_into_words=True)\n",
        "\n",
        "X_train = [str(ex) + EOS_TOKEN for ex in X_train]\n",
        "X_test = [str(ex) + EOS_TOKEN for ex in X_test]\n",
        "\n",
        "X_train_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH,\n",
        "                      truncation=True, padding=\"max_length\", add_special_tokens=True)['input_ids'] for x in X_train]\n",
        "X_test_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH,\n",
        "                     truncation=True, padding=\"max_length\", add_special_tokens=True)['input_ids'] for x in X_test]\n",
        "\n",
        "X_train_in = tf.squeeze(tf.convert_to_tensor(X_train_), axis=1)\n",
        "X_test_in = tf.squeeze(tf.convert_to_tensor(X_test_), axis=1)\n",
        "\n",
        "X_train_mask_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH,\n",
        "                           truncation=True, padding=\"max_length\", add_special_tokens=True)[\"attention_mask\"] for x in X_train]\n",
        "X_test_mask_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH,\n",
        "                          truncation=True, padding=\"max_length\", add_special_tokens=True)[\"attention_mask\"] for x in X_test]\n",
        "\n",
        "X_train_mask = tf.squeeze(tf.convert_to_tensor(X_train_mask_), axis=1)\n",
        "X_test_mask = tf.squeeze(tf.convert_to_tensor(X_test_mask_), axis=1)\n",
        "\n",
        "\n",
        "model = TFGPT2Model.from_pretrained(\"gpt2\", use_cache=False,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id)\n",
        "model.training = True\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "input_ = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
        "mask_ = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
        "x = model(input_, attention_mask=mask_)\n",
        "x = tf.reduce_mean(x.last_hidden_state, axis=1)\n",
        "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "output = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "clf = tf.keras.Model([input_, mask_], output)\n",
        "\n",
        "base_learning_rate = 0.0005\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "clf.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"accuracy\", verbose=1, patience=3, restore_best_weights=True)\n",
        "\n",
        "def map_sentiment(value):\n",
        "  if value == 'Negative':\n",
        "    return 0\n",
        "  if value == 'Neutral':\n",
        "    return 1\n",
        "  if value == 'Positive':\n",
        "    return 2\n",
        "\n",
        "y_train_ = y_train.map(map_sentiment)\n",
        "y_test_ = y_test.map(map_sentiment)\n",
        "\n",
        "y_train_in = tf.constant(y_train_, dtype=tf.int32)\n",
        "y_test_in = tf.constant(y_test_, dtype=tf.int32)\n",
        "\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "\n",
        "def train_model():\n",
        "    clf.fit([X_train_in, X_train_mask], y_train_in, epochs=5, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "train_time, train_energy_j, train_emissions_kg = measure_energy_and_time(train_model)\n",
        "print(f\"Training completed in {train_time:.2f}s, Energy: {train_energy_j:.2f}J, Emissions: {train_emissions_kg:.4f}kg CO2\")\n",
        "log_results(\"GPT2_TransferLearning\", \"Training\", train_time, train_energy_j, train_emissions_kg)\n",
        "\n",
        "\n",
        "print(\"Evaluating on test set...\")\n",
        "eval_time, eval_energy_j, eval_emissions_kg = measure_energy_and_time(clf.evaluate, [X_test_in, X_test_mask], y_test_in)\n",
        "print(f\"Evaluation completed in {eval_time:.2f}s, Energy: {eval_energy_j:.2f}J, Emissions: {eval_emissions_kg:.4f}kg CO2\")\n",
        "log_results(\"GPT2_TransferLearning\", \"Evaluation\", eval_time, eval_energy_j, eval_emissions_kg)\n",
        "\n",
        "clf.training = False\n",
        "y_pred = clf.predict([X_test_in, X_test_mask])\n",
        "\n",
        "print(\"Done. Results saved to:\", RESULTS_CSV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKTi6wwKKL9f",
        "outputId": "8ee037c0-af74-4f29-a9ef-910664044509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (12.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pynvml) (12.560.30)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2Model.\n",
            "\n",
            "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - ETA: 0s - loss: 6.8715 - accuracy: 0.2984"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 4s 993ms/step - loss: 6.8715 - accuracy: 0.2984 - val_loss: 8.1579 - val_accuracy: 0.1250\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 6.4132 - accuracy: 0.3065 - val_loss: 6.4392 - val_accuracy: 0.1250\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 4s 983ms/step - loss: 5.2451 - accuracy: 0.3145 - val_loss: 4.8973 - val_accuracy: 0.1250\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 4.5685 - accuracy: 0.3468 - val_loss: 3.6648 - val_accuracy: 0.1250\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 3.8470 - accuracy: 0.3468 - val_loss: 2.8701 - val_accuracy: 0.2500\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Training completed in 20.58s, Energy: 1066.56J, Emissions: 0.0001kg CO2\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 344ms/step - loss: 3.0356 - accuracy: 0.2830\n",
            "Evaluation completed in 0.81s, Energy: 49.05J, Emissions: 0.0000kg CO2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 213ms/step\n",
            "Done. Results saved to: energy_measurements.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Frezzing"
      ],
      "metadata": {
        "id": "wz43Ph7rMzds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer, TFGPT2Model\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import time\n",
        "import psutil\n",
        "import threading\n",
        "import csv\n",
        "import os\n",
        "import pynvml\n",
        "\n",
        "\n",
        "CARBON_INTENSITY = 0.4\n",
        "RESULTS_CSV = \"energy_measurements_freze_gpu.csv\"\n",
        "GPU_DETAILS_CSV = \"gpu_details_freze_gpu.csv\"\n",
        "USE_GPU = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "\n",
        "def get_gpu_details():\n",
        "    pynvml.nvmlInit()\n",
        "    device_count = pynvml.nvmlDeviceGetCount()\n",
        "    details = []\n",
        "\n",
        "    for i in range(device_count):\n",
        "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
        "        name = pynvml.nvmlDeviceGetName(handle)  # No need to decode\n",
        "        memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "        utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
        "        architecture = pynvml.nvmlSystemGetCudaDriverVersion()\n",
        "\n",
        "        details.append({\n",
        "            \"GPU\": name,\n",
        "            \"Memory Total (MB)\": memory_info.total // (1024 ** 2),\n",
        "            \"Memory Free (MB)\": memory_info.free // (1024 ** 2),\n",
        "            \"Memory Used (MB)\": memory_info.used // (1024 ** 2),\n",
        "            \"GPU Utilization (%)\": utilization.gpu,\n",
        "            \"Memory Utilization (%)\": utilization.memory,\n",
        "            \"CUDA Version\": architecture\n",
        "        })\n",
        "\n",
        "    pynvml.nvmlShutdown()\n",
        "    return details\n",
        "\n",
        "\n",
        "def get_gpu_power():\n",
        "    if USE_GPU:\n",
        "        result = subprocess.run(\n",
        "            [\"nvidia-smi\", \"--query-gpu=power.draw\", \"--format=csv,nounits,noheader\"],\n",
        "            stdout=subprocess.PIPE, text=True)\n",
        "        return float(result.stdout.strip())\n",
        "    return 0.0\n",
        "\n",
        "def get_cpu_power_estimate():\n",
        "    cpu_util = psutil.cpu_percent()\n",
        "    estimated_cpu_power = (cpu_util / 100.0) * 50\n",
        "    return estimated_cpu_power\n",
        "\n",
        "def measure_energy_and_time(func, *args, **kwargs):\n",
        "    start_time = time.time()\n",
        "    energy_gpu_joules = 0.0\n",
        "    energy_cpu_joules = 0.0\n",
        "    interval = 0.1\n",
        "\n",
        "    def target():\n",
        "        func(*args, **kwargs)\n",
        "\n",
        "    thread = threading.Thread(target=target)\n",
        "    thread.start()\n",
        "\n",
        "    while thread.is_alive():\n",
        "        gpu_watts = get_gpu_power()\n",
        "        cpu_watts = get_cpu_power_estimate()\n",
        "        time.sleep(interval)\n",
        "        energy_gpu_joules += gpu_watts * interval\n",
        "        energy_cpu_joules += cpu_watts * interval\n",
        "\n",
        "    thread.join()\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_energy_joules = energy_gpu_joules + energy_cpu_joules\n",
        "    total_energy_kwh = total_energy_joules * 2.77778e-7\n",
        "    emissions_kg = total_energy_kwh * CARBON_INTENSITY\n",
        "\n",
        "    return total_time, total_energy_joules, emissions_kg\n",
        "\n",
        "def log_results(task_name, phase, total_time, energy_joules, emissions_kg, filename=RESULTS_CSV):\n",
        "    file_exists = os.path.isfile(filename)\n",
        "    with open(filename, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        if not file_exists:\n",
        "            writer.writerow([\"Task\", \"Phase\", \"Time(s)\", \"Energy(J)\", \"Emissions(kgCO2)\"])\n",
        "        writer.writerow([task_name, phase, total_time, energy_joules, emissions_kg])\n",
        "\n",
        "def log_gpu_details(details, filename=GPU_DETAILS_CSV):\n",
        "    file_exists = os.path.isfile(filename)\n",
        "    with open(filename, 'a', newline='') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=details[0].keys())\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "        writer.writerows(details)\n",
        "\n",
        "\n",
        "df = pd.read_csv('tweets_processed.csv')\n",
        "\n",
        "df = df.sample(frac=0.6, random_state=42).reset_index(drop=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['lemmatized_tweets']\n",
        "y = df['VADER_sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
        "\n",
        "\n",
        "MAX_LENGTH = math.ceil((X_train.apply(lambda x: len(str(x).split())).mean()))+2\n",
        "\n",
        "PAD_TOKEN = \"<|pad|>\"\n",
        "EOS_TOKEN = \"<|endoftext|>\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",\n",
        "    pad_token=PAD_TOKEN,\n",
        "    eos_token=EOS_TOKEN,\n",
        "    max_length=MAX_LENGTH,\n",
        "    is_split_into_words=True)\n",
        "\n",
        "X_train = [str(ex) + EOS_TOKEN for ex in X_train]\n",
        "X_test = [str(ex) + EOS_TOKEN for ex in X_test]\n",
        "\n",
        "X_train_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH,\n",
        "                      truncation=True, padding=\"max_length\", add_special_tokens=True)['input_ids'] for x in X_train]\n",
        "X_test_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH,\n",
        "                     truncation=True, padding=\"max_length\", add_special_tokens=True)['input_ids'] for x in X_test]\n",
        "\n",
        "X_train_in = tf.squeeze(tf.convert_to_tensor(X_train_), axis=1)\n",
        "X_test_in = tf.squeeze(tf.convert_to_tensor(X_test_), axis=1)\n",
        "\n",
        "X_train_mask_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH,\n",
        "                           truncation=True, padding=\"max_length\", add_special_tokens=True)[\"attention_mask\"] for x in X_train]\n",
        "X_test_mask_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH,\n",
        "                          truncation=True, padding=\"max_length\", add_special_tokens=True)[\"attention_mask\"] for x in X_test]\n",
        "\n",
        "X_train_mask = tf.squeeze(tf.convert_to_tensor(X_train_mask_), axis=1)\n",
        "X_test_mask = tf.squeeze(tf.convert_to_tensor(X_test_mask_), axis=1)\n",
        "\n",
        "\n",
        "model = TFGPT2Model.from_pretrained(\"gpt2\", use_cache=False,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id)\n",
        "model.training = True\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "input_ = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
        "mask_ = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
        "x = model(input_, attention_mask=mask_)\n",
        "x = tf.reduce_mean(x.last_hidden_state, axis=1)\n",
        "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "output = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "clf = tf.keras.Model([input_, mask_], output)\n",
        "\n",
        "base_learning_rate = 0.0005\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "clf.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"accuracy\", verbose=1, patience=3, restore_best_weights=True)\n",
        "\n",
        "def map_sentiment(value):\n",
        "  if value == 'Negative':\n",
        "    return 0\n",
        "  if value == 'Neutral':\n",
        "    return 1\n",
        "  if value == 'Positive':\n",
        "    return 2\n",
        "\n",
        "y_train_ = y_train.map(map_sentiment)\n",
        "y_test_ = y_test.map(map_sentiment)\n",
        "\n",
        "y_train_in = tf.constant(y_train_, dtype=tf.int32)\n",
        "y_test_in = tf.constant(y_test_, dtype=tf.int32)\n",
        "\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "\n",
        "def train_model():\n",
        "    clf.fit([X_train_in, X_train_mask], y_train_in, epochs=30, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "\n",
        "gpu_details = get_gpu_details()\n",
        "print(\"GPU Details and Insights:\")\n",
        "for detail in gpu_details:\n",
        "    print(detail)\n",
        "log_gpu_details(gpu_details)\n",
        "\n",
        "\n",
        "print(\"Starting training...\")\n",
        "train_time, train_energy_j, train_emissions_kg = measure_energy_and_time(train_model)\n",
        "print(f\"Training completed in {train_time:.2f}s, Energy: {train_energy_j:.2f}J, Emissions: {train_emissions_kg:.4f}kg CO2\")\n",
        "log_results(\"GPT2_TransferLearning\", \"Training\", train_time, train_energy_j, train_emissions_kg)\n",
        "\n",
        "print(\"Evaluating on test set...\")\n",
        "eval_time, eval_energy_j, eval_emissions_kg = measure_energy_and_time(clf.evaluate, [X_test_in, X_test_mask], y_test_in)\n",
        "print(f\"Evaluation completed in {eval_time:.2f}s, Energy: {eval_energy_j:.2f}J, Emissions: {eval_emissions_kg:.4f}kg CO2\")\n",
        "log_results(\"GPT2_TransferLearning\", \"Evaluation\", eval_time, eval_energy_j, eval_emissions_kg)\n",
        "\n",
        "clf.training = False\n",
        "y_pred = clf.predict([X_test_in, X_test_mask])\n",
        "\n",
        "print(\"Done. Results saved to:\", RESULTS_CSV)\n"
      ],
      "metadata": {
        "id": "Qv2ePuV7No0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae608fd-b097-4747-abaa-743957d7015e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (12.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pynvml) (12.560.30)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2Model.\n",
            "\n",
            "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Details and Insights:\n",
            "{'GPU': 'Tesla T4', 'Memory Total (MB)': 15360, 'Memory Free (MB)': 6793, 'Memory Used (MB)': 8566, 'GPU Utilization (%)': 0, 'Memory Utilization (%)': 0, 'CUDA Version': 12020}\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.8019 - accuracy: 0.3533"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 27s 1s/step - loss: 1.8019 - accuracy: 0.3533 - val_loss: 1.0890 - val_accuracy: 0.4392\n",
            "Epoch 2/30\n",
            "24/24 [==============================] - 25s 1s/step - loss: 1.1001 - accuracy: 0.3732 - val_loss: 1.0596 - val_accuracy: 0.4603\n",
            "Epoch 3/30\n",
            "24/24 [==============================] - 25s 1s/step - loss: 1.0729 - accuracy: 0.4170 - val_loss: 1.0744 - val_accuracy: 0.3228\n",
            "Epoch 4/30\n",
            "24/24 [==============================] - 25s 1s/step - loss: 1.0762 - accuracy: 0.3559 - val_loss: 1.0937 - val_accuracy: 0.3228\n",
            "Epoch 5/30\n",
            "24/24 [==============================] - 25s 1s/step - loss: 1.0842 - accuracy: 0.3679 - val_loss: 1.0790 - val_accuracy: 0.3228\n",
            "Epoch 6/30\n",
            "24/24 [==============================] - 26s 1s/step - loss: 1.0688 - accuracy: 0.3665 - val_loss: 1.0775 - val_accuracy: 0.4603\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "Training completed in 154.58s, Energy: 9198.47J, Emissions: 0.0010kg CO2\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 224ms/step - loss: 1.0654 - accuracy: 0.3599\n",
            "Evaluation completed in 50.29s, Energy: 1819.57J, Emissions: 0.0002kg CO2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 200ms/step\n",
            "Done. Results saved to: energy_measurements_freze_gpu.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Iq28o20ORj4T",
        "outputId": "3b363fd8-d5bd-46e8-ca7c-bde7ba69d0d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 10 13:23:09 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k_D6f6Rw60qi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}